close(read.binfile2)
## decrypt file with private key + print it on screen
decrypted_message <- rawToChar(PKI.decrypt(reread.encrypted.data, prv.key.loaded))
print(decrypted_message)
## second message
decrypted_message2 <- rawToChar(PKI.decrypt(reread.encrypted.data2, prv.key.loaded))
print(decrypted_message2)
rm(list = ls())
library(PKI)
rm(list = ls())
# 1) Generate keypair for ceu.edu and save it in pem format ------------------
key <- PKI.genRSAkey(bits = 2048L)
prv.pem <- PKI.save.key(key, private=TRUE)
pub.pem <- PKI.save.key(key, private=FALSE)
# 2) ceu.edu sends private pem file to visitor ------------------------------------
write(pub.pem, file="id_ceu_edu.pub")
write(prv.pem, file="id_ceu_edu")
# 3) visitor creates encrypted message using CEU's public key ------------------------
##load pem format and convert to key
pub.pem.loaded <- scan("id_ceu_edu.pub", what='list', sep='\n')
pub.key.loaded <- PKI.load.key(pub.pem.loaded)
## encrprypt random message with CEU's private key
message <- 'Something that should be encrpyted'
bytes.to.encode = charToRaw(message)
encrypted <- PKI.encrypt(bytes.to.encode, pub.key.loaded)
# 4) visitor sends encrypted message to CEU ----------------------------------
writeBin(encrypted, file("encrypted_message.dat", "wb"))
close(file("encrypted_message.dat", "wb"))
# Adding second message ---------------------------------------------------
pub.pem.loaded <- scan("id_ceu_edu.pub", what='list', sep='\n')
pub.key.loaded <- PKI.load.key(pub.pem.loaded)
message2 <- 'This shall be the big big message'
bytes.to.encode = charToRaw(message2)
encrypted <- PKI.encrypt(bytes.to.encode, pub.key.loaded)
writeBin(encrypted, file("encrypted_message2.dat", "wb"))
close(file("encrypted_message2.dat", "wb"))
# 5) CEU reads it's private key from disk + decrypts message -----------------
##load private key from disk + convert to key
prv.pem.loaded <- scan("id_ceu_edu", what='list', sep='\n')
prv.key.loaded <- PKI.load.key(prv.pem.loaded)
## read encrypted file from disk
read.binfile <- file("encrypted_message.dat", "rb")
reread.encrypted.data <- readBin(read.binfile, raw(), n=999999999)
close(read.binfile)
## read second message
read.binfile2 <- file("encrypted_message2.dat", "rb")
reread.encrypted.data2 <- readBin(read.binfile2, raw(), n=999999999)
close(read.binfile2)
## decrypt file with private key + print it on screen
decrypted_message <- rawToChar(PKI.decrypt(reread.encrypted.data, prv.key.loaded))
print(decrypted_message)
## second message
decrypted_message2 <- rawToChar(PKI.decrypt(reread.encrypted.data2, prv.key.loaded))
print(decrypted_message2)
## read encrypted file from disk
read.binfile <- file("encrypted_message.dat", "rb")
reread.encrypted.data <- readBin(read.binfile, raw(), n=999999999)
close(read.binfile)
## decrypt file with private key + print it on screen
decrypted_message <- rawToChar(PKI.decrypt(reread.encrypted.data, prv.key.loaded))
print(decrypted_message)
library(PKI)
rm(list = ls())
# 1) Generate keypair for ceu.edu and save it in pem format ------------------
key <- PKI.genRSAkey(bits = 2048L)
prv.pem <- PKI.save.key(key, private=TRUE)
pub.pem <- PKI.save.key(key, private=FALSE)
# 2) ceu.edu sends private pem file to visitor ------------------------------------
write(pub.pem, file="id_ceu_edu.pub")
write(prv.pem, file="id_ceu_edu")
# 3) visitor creates encrypted message using CEU's public key ------------------------
##load pem format and convert to key
pub.pem.loaded <- scan("id_ceu_edu.pub", what='list', sep='\n')
pub.key.loaded <- PKI.load.key(pub.pem.loaded)
## encrprypt random message with CEU's private key
message <- 'Something that should be encrpyted'
bytes.to.encode = charToRaw(message)
encrypted <- PKI.encrypt(bytes.to.encode, pub.key.loaded)
# 4) visitor sends encrypted message to CEU ----------------------------------
writeBin(encrypted, file("encrypted_message.dat", "wb"))
close(file("encrypted_message.dat", "wb"))
# Adding second message ---------------------------------------------------
pub.pem.loaded <- scan("id_ceu_edu.pub", what='list', sep='\n')
pub.key.loaded <- PKI.load.key(pub.pem.loaded)
message2 <- 'This shall be the big big message'
bytes.to.encode = charToRaw(message2)
encrypted <- PKI.encrypt(bytes.to.encode, pub.key.loaded)
writeBin(encrypted, file("encrypted_message2.dat", "wb"))
close(file("encrypted_message2.dat", "wb"))
# 5) CEU reads it's private key from disk + decrypts message -----------------
##load private key from disk + convert to key
prv.pem.loaded <- scan("id_ceu_edu", what='list', sep='\n')
prv.key.loaded <- PKI.load.key(prv.pem.loaded)
## read encrypted file from disk
read.binfile <- file("encrypted_message.dat", "rb")
reread.encrypted.data <- readBin(read.binfile, raw(), n=999999999)
close(read.binfile)
## read second message
read.binfile2 <- file("encrypted_message2.dat", "rb")
reread.encrypted.data2 <- readBin(read.binfile2, raw(), n=999999999)
close(read.binfile2)
## decrypt file with private key + print it on screen
decrypted_message <- rawToChar(PKI.decrypt(reread.encrypted.data, prv.key.loaded))
print(decrypted_message)
knitr::opts_chunk$set(echo = TRUE)
## linear
p1 <- lm_robust( ln_death_pc ~ ln_conf_pc , data = df , se_type = "HC2" )
library(tidyverse)
library(moments)
library(xtable)
library(ggpubr)
require(scales)
library(lspline)
library(estimatr)
library(texreg)
library(ggthemes)
#library(ggcorrplot)
data_in <- "C:/Users/T450s/Desktop/programming/git/ba_da2/Assignment_1/data/clean/"
df <- read_csv(paste0(data_in,"covid_pop_20201015_clean.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moments)
library(xtable)
library(ggpubr)
require(scales)
library(lspline)
library(estimatr)
library(texreg)
library(ggthemes)
#library(ggcorrplot)
data_in <- "C:/Users/T450s/Desktop/programming/git/ba_da2/Assignment_1/data/clean/"
df <- read_csv(paste0(data_in,"covid_pop_20201015_clean.csv"))
df <- df %>%
filter(deaths != 0) %>%
mutate(
death_pc = as.numeric(deaths/(population/1000000)),
conf_pc = as.numeric(confirmed / (population/1000000)),
mortality = as.numeric(deaths/confirmed),
ln_conf_pc = log( conf_pc ),
ln_death_pc = log( death_pc )
)
death_pc_sum <- df %>% summarise(
variable = 'Death per capita',
mean     = mean(death_pc),
median   = median(death_pc),
std      = sd(death_pc),
iq_range = IQR(death_pc),
min      = min(death_pc),
max      = max(death_pc),
skew     = skewness(death_pc),
numObs   = sum( !is.na( death_pc ) ) )
conf_pc_sum <- df %>% summarise(
variable = 'Confirmed cases per capita',
mean     = mean(conf_pc),
median   = median(conf_pc),
std      = sd(conf_pc),
iq_range = IQR(conf_pc),
min      = min(conf_pc),
max      = max(conf_pc),
skew     = skewness(conf_pc),
numObs   = sum( !is.na( conf_pc ) ) )
df_summary <- death_pc_sum %>% add_row( conf_pc_sum )
xtb <- xtable(df_summary,type = "latex", caption = "Summary statistics of `x` and `y` variables")
reg1 <- lm_robust( ln_death_pc ~ ln_conf_pc , data = df , se_type = "HC2" )
tab<- tidy(reg1)
tab <-  tab %>%
filter(term == 'ln_conf_pc')  %>%
transmute(
variable=term,
estimate = estimate,
std.error = std.error,
statistic = statistic,
p.value = p.value,
conf.low = conf.low,
conf.high = conf.high)
xtb <- xtable(tab,type = "latex", caption = "Hypothesis testing for the slope of the regression")
print(xtb,comment = FALSE, include.rownames = FALSE)
## linear
p1 <- lm_robust( ln_death_pc ~ ln_conf_pc , data = df , se_type = "HC2" )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( method = lm , color = 'red' )
## quadratic
p2 <- lm_robust( ln_death_pc ~ ln_conf_pc + ln_conf_pc_sq , data = df )
## adding quadratic variable
df <- df %>% mutate( ln_conf_pc_sq = ln_conf_pc^2
)
## linear
p1 <- lm_robust( ln_death_pc ~ ln_conf_pc , data = df , se_type = "HC2" )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( method = lm , color = 'red' )
## quadratic
p2 <- lm_robust( ln_death_pc ~ ln_conf_pc + ln_conf_pc_sq , data = df )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( formula = y ~ poly(x,2) , method = lm , color = 'red' )
## pls
ln_cutoff <- log(c(200,3000))
p3 <- lm_robust(ln_death_pc ~ lspline( ln_conf_pc , ln_cutoff ), data = df )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( formula = y ~ lspline(x,ln_cutoff) , method = lm , color = 'red' )
## weighted
p4 <- lm_robust(ln_death_pc ~ ln_conf_pc, data = df , weights = population)
ggplot(data = df, aes(x = ln_conf_pc, y = ln_death_pc)) +
geom_point(data = df, aes(size=population),  color = 'blue', shape = 16, alpha = 0.6,  show.legend=F) +
geom_smooth(aes(weight = population), method = "lm", color='red')
ggarrange(p1, p2,p3,p4, nrow = 2 )
#reg1 is already defined in an earlier chunk
reg2 <- lm_robust( ln_death_pc ~ ln_conf_pc + ln_conf_pc_sq , data = df )
reg3 <- lm_robust(ln_death_pc ~ lspline( ln_conf_pc , ln_cutoff ), data = df )
reg4 <- lm_robust(ln_death_pc ~ ln_conf_pc, data = df , weights = population)
htmlreg( list(reg1 , reg2 , reg3 , reg4),
type = 'html',
custom.model.names = c("Confirmed/capita - linear","Confirmed/capita - quadratic",
"Confirmed/capita - PLS",'Confirmed/capita - weighted linear'),
caption = "Modeling Covid-19 caused deaths and confirmed cases")
library(tidyverse)
require(scales)
library(lspline)
library(estimatr)
library(texreg)
library(ggthemes)
library(xtable)
library(car)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df<- read_csv('../data/clean/covid_pop_20201015_clean.csv')
# EDA ---------------------------------------------------------------------
## histograms look to be skewed to the right
df %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~key, scales = "free") +
geom_histogram()+
theme_wsj() +
scale_fill_wsj()
##  create per capita variables
colnames(df)
df <- df %>%
mutate(
death_pc = as.numeric(deaths/(population/1000000)),
conf_pc = as.numeric(confirmed / (population/1000000)),
mortality = as.numeric(deaths/confirmed)
)
## plotting
## a) level-level - scaled
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess") +
labs(x='Infected per 1 m capita',y='Dead per 1m capita')
## two extreme values in terms of confirmed cases/1m people: Qatar, Bahrein
## Otherwise there seems to be a positive trend
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess")+
scale_x_continuous( trans = log_trans(),  breaks = c(1,2,5,10,20,50,100,200,500,1000,10000) )+
labs(x='Infected per 1 m capita - ln scale',y='Dead per 1m capita')
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess")+
scale_x_continuous( trans = log_trans(),  breaks = c(1,2,5,10,20,50,100,200,500,1000,3000,10000) )+
scale_y_continuous( trans = log_trans(), breaks = c(1,20,200,400) )+
labs(x='Infected per 1 m capita - ln scale',y='Dead per 1m capita - ln scale')
## Conclusion - log-log transformation seems to be giving a good fit
## we will remove cases where nobody died, so that ln transform can happen
df <- df %>%  filter(deaths != 0)
df <- df %>% mutate( ln_conf_pc = log( conf_pc ),
ln_death_pc = log( death_pc ) )
# Regression tests --------------------------------------------------------
## We create variables to use polinomials later on
df <- df %>% mutate( ln_conf_pc_sq = ln_conf_pc^2,
ln_conf_pc_cb = ln_conf_pc^3
)
## linear without log transformation
colnames(df)
reg0 <- lm_robust( death_pc ~ conf_pc , data = df , se_type = "HC2" )
summary(reg0)
library(WDI)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#Date: 05/10/2020
#Y: Number of registered death per capita
#X: Number of registered case per capita
#First,  getting the csv from Johns Hopkins University's page
url <- 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports'
date <- '10-05-2020'
csv_location <- paste0(url,'/',date,'.csv')
covid_data <- read_csv(csv_location)
# Then we get population data from WDI
population_data <- WDI(indicator=c('SP.POP.TOTL'),
country="all", start=2019, end=2019)
#finally, writing out raw files to github
write_csv(covid_data, '../data/raw/covid_20201005_raw.csv')
write_csv(population_data, '../data/raw/population_2019_raw.csv')
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Let's clean population data first per guidance in Coding1 - Class 8 --------
## load data
df_population <- read_csv("../data/raw/population_2019_raw.csv")
## special cases
to_drop <- c("EU","HK","OE")
to_retain <- c("XK","ZA","ZM","ZW")
## filtering out grouped entitites
### a) those that have an integer in their iso2c
df_population <- df_population %>%
filter(!grepl("[[:digit:]]", df_population$iso2c))
### b) further manually spotted grouped entitites e.g. EU
df_population <- df_population %>%
filter(!grepl( paste( to_drop , collapse="|"), df_population$iso2c ))
### c) most records that have X, or Z in their iso2c except `to_retain` vector
fl_iso2c <- substr(df_population$iso2c, 1, 1)
df_population <- df_population %>%
filter(!(grepl( "X", fl_iso2c ) | grepl( "Z", fl_iso2c ) &
!grepl( paste( to_retain , collapse="|"),
df_population$iso2c ) ) )
### d) NAs or NaNs
df_population <-
df_population %>%
filter(complete.cases(df_population) | is.na(df_population$iso2c))
## keep columns needed
df_population <-
df_population %>%
transmute( country = country,
population=SP.POP.TOTL)
# Let's continue with covid data ------------------------------------------
## First we load the data
df_covid <- read_csv( "../data/raw/covid_20201005_raw.csv" )
## I do 3 things: 1) group by country 2) sum records that appera multiple
## times for a given country - since they were broken out to regions and 3)
## naturally unusued columns not defined in summarise function are dropped
df_covid <- df_covid %>%
mutate(country=Country_Region) %>%
group_by(country) %>%
summarise(
confirmed = sum( Confirmed, na.rm = TRUE ),
deaths = sum( Deaths, na.rm = TRUE ),
recovered = sum( Recovered , na.rm = TRUE),
active = sum( Active, na.rm = TRUE ) )
# Merging dataframes ------------------------------------------------------
## merging dataframes with full join
joined_df <- full_join(df_covid,df_population, by = 'country')
## we will have a lot of partial matches, let's look at observations with NAs
temp_df <- joined_df %>%
filter(!complete.cases(joined_df)) %>%
transmute(country=country) %>%
arrange(country)
## manually picking out records to be renamed
keep_names <- c(
'Brunei', 'Bahamas', 'Laos', 'Syria',
'Egypt', 'Czech Republic',
'Congo', 'Congo', 'Congo', 'Congo',
'Kyrgyzstan', 'Korea, South', 'Iran', 'Gambia',
'Saint Lucia', 'Saint Kitts and Nevis', 'Slovakia','Russia',
'St. Vincent and the Grenadines','United States','Venezuela', 'Yemen')
change_names <- c(
'Brunei Darussalam','Bahamas, The', 'Lao PDR', 'Syrian Arab Republic',
'Egypt, Arab Rep.', 'Czechia',
'Congo, Dem. Rep.', 'Congo, Rep.', 'Congo (Kinshasa)','Congo (Brazzaville)',
'Kyrgyz Republic', 'Korea, Rep.', 'Iran, Islamic Rep.', 'Gambia, The',
'St. Lucia','St. Kitts and Nevis', 'Slovak Republic', 'Russian Federation',
'Saint Vincent and the Grenadines','US','Venezuela, RB','Yemen, Rep.')
## renaming countries with partial matches
for ( i in seq_along( keep_names ) ){
joined_df$country[ joined_df $country == change_names[ i ] ] <- keep_names[ i ]
}
## summing up population and covid cases
joined_df<- joined_df %>%
group_by(country) %>%
summarise(
confirmed = sum( confirmed, na.rm = TRUE ),
deaths = sum( deaths, na.rm = TRUE),
recovered = sum( recovered, na.rm = TRUE ),
active = sum( active, na.rm = TRUE ),
population = sum(population, na.rm = TRUE))
## I still have records that should be filtered out as with full join
## I added countries that are actually not present in both tables, but due to
## summing up, they are not NA anymore.
## I checked source db and it can't be that
##  there are 0 confirmed cases or
##  0 population for a country, so I will filter those out
final_df <- joined_df %>%  filter(
!(population == 0 | confirmed ==0)
)
## I will check if I have any NAs left
sum(complete.cases(final_df)) == nrow(final_df)
## No NAs left
write_csv(final_df, '../data/clean/covid_pop_20201005_clean.csv')
library(tidyverse)
require(scales)
library(lspline)
library(estimatr)
library(texreg)
library(ggthemes)
library(xtable)
library(car)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df<- read_csv('../data/clean/covid_pop_20201005_clean.csv')
# EDA ---------------------------------------------------------------------
## histograms look to be skewed to the right
df %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~key, scales = "free") +
geom_histogram()+
theme_wsj() +
scale_fill_wsj()
##  create per capita variables
colnames(df)
df <- df %>%
mutate(
death_pc = as.numeric(deaths/(population/1000000)),
conf_pc = as.numeric(confirmed / (population/1000000)),
mortality = as.numeric(deaths/confirmed)
)
## plotting
## a) level-level - scaled
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess") +
labs(x='Infected per 1 m capita',y='Dead per 1m capita')
## two extreme values in terms of confirmed cases/1m people: Qatar, Bahrein
## Otherwise there seems to be a positive trend
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess")+
scale_x_continuous( trans = log_trans(),  breaks = c(1,2,5,10,20,50,100,200,500,1000,10000) )+
labs(x='Infected per 1 m capita - ln scale',y='Dead per 1m capita')
ggplot( df , aes(x = conf_pc, y =death_pc )) +
geom_point() +
geom_smooth(method="loess")+
scale_x_continuous( trans = log_trans(),  breaks = c(1,2,5,10,20,50,100,200,500,1000,3000,10000) )+
scale_y_continuous( trans = log_trans(), breaks = c(1,20,200,400) )+
labs(x='Infected per 1 m capita - ln scale',y='Dead per 1m capita - ln scale')
## Conclusion - log-log transformation seems to be giving a good fit
## we will remove cases where nobody died, so that ln transform can happen
df <- df %>%  filter(deaths != 0)
df <- df %>% mutate( ln_conf_pc = log( conf_pc ),
ln_death_pc = log( death_pc ) )
# Regression tests --------------------------------------------------------
## We create variables to use polinomials later on
df <- df %>% mutate( ln_conf_pc_sq = ln_conf_pc^2,
ln_conf_pc_cb = ln_conf_pc^3
)
## linear
reg1 <- lm_robust( ln_death_pc ~ ln_conf_pc , data = df , se_type = "HC2" )
summary( reg1 )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( method = lm , color = 'red' )
## quadratic
reg2 <- lm_robust( ln_death_pc ~ ln_conf_pc + ln_conf_pc_sq , data = df )
summary( reg2 )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( formula = y ~ poly(x,2) , method = lm , color = 'red' )
## pls
ln_cutoff <- log(c(200,3000))
reg3 <- lm_robust(ln_death_pc ~ lspline( ln_conf_pc , ln_cutoff ), data = df )
summary( reg3 )
ggplot( data = df, aes( x = ln_conf_pc, y = ln_death_pc ) ) +
geom_point( color='blue') +
geom_smooth( formula = y ~ lspline(x,ln_cutoff) , method = lm , color = 'red' )
## weighted
reg4 <- lm_robust(ln_death_pc ~ ln_conf_pc, data = df , weights = population)
summary( reg4 )
ggplot(data = df, aes(x = ln_conf_pc, y = ln_death_pc)) +
geom_point(data = df, aes(size=population),  color = 'blue', shape = 16, alpha = 0.6,  show.legend=F) +
geom_smooth(aes(weight = population), method = "lm", color='red')
#scale_size(range = c(1, 15)) +
#coord_cartesian(ylim = c(50, 85)) +
#labs(x = "ln(GDP per capita, thousand US dollars) ",y = "Life expectancy  (years)")+
#annotate("text", x = 4, y = 80, label = "USA", size=5)+
#annotate("text", x = 2.7, y = 79, label = "China", size=5)+
#annotate("text", x = 2,  y = 68, label = "India", size=5)
# Choose model ------------------------------------------------------------
data_out <- '../out/'
htmlreg( list(reg1 , reg2 , reg3 , reg4),
type = 'html',
custom.model.names = c("Confirmed/capita - linear","Confirmed/capita - quadratic",
"Confirmed/capita - PLS",'Confirmed/capita - weighted linear'),
caption = "Modeling Covid-19 caused deaths and confirmed cases",
file = paste0( data_out ,'model_comparison.html'), include.ci = FALSE)
# Prediction errors -------------------------------------------------------
# Get the predicted y values from the model
df$reg1_y_pred <- reg1$fitted.values
# Calculate the errors of the model
df$reg1_res <- df$ln_death_pc - df$reg1_y_pred
# Find countries with largest negative errors
df %>% top_n( -5 , reg1_res ) %>%
select( country , ln_death_pc , reg1_y_pred , reg1_res )
# Find countries with largest positive errors
df %>% top_n( 5 , reg1_res ) %>%
select( country , ln_death_pc , reg1_y_pred , reg1_res )
# Testing hypothesis ------------------------------------------------------
# Test if beta = 0
lin <-linearHypothesis( reg1 , "ln_conf_pc = 0")
tab<- tidy(reg1)
tab <-  tab %>%
filter(term == 'ln_conf_pc')  %>%
transmute(
variable=term,
estimate = estimate,
std.error = std.error,
statistic = statistic,
p.value = p.value,
conf.low = conf.low,
conf.high = conf.high)
dataf <- reg1
texreg(list(reg1 , reg2 , reg3 , reg4), table = FALSE, use.packages = FALSE, caption = 'Something about covid')
